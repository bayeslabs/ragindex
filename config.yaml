data:
  corpus: [./ragindex/data/sample_data/rag_for_llms.pdf]
  benchmark_data: ''
  save_dir: "./ragindex/data"
retriever:
  chunk_size: 400
  text_overlap: 50
  top_k: 3
  vector_store:
    embedding: [all_minilm_embeddings]
    database: [Chroma]
    persist_directory: [./ragindex/vector_stores/]
    chunks: ["this is my 1st chunk", "this is my second chunk"]
  rerankers: [cross_encoder]
  retriever_benchmark_metrics:
    context_precision: True
    context_recall: False
generator:
  context_given: "yes"   #["yes","no"]
  chain_type: "simple"
  models:
    model_type: "hugging_face"
    open_ai_model: ["gpt-3.5-turbo"]
    hugging_face_model: ["tiiuae/falcon-7b-instruct"]
  model_config:
    max_tokens: 256
    temperature: [0.1]
  prompt_template:
    domain: "Life Science"
    prompt_type: general
  generation_benchmark_metrics:
    answer_relevancy: True
    answer_similarity: False
